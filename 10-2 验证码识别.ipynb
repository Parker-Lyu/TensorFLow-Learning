{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from nets import nets_factory\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_SET = [str(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_SET_LEN = len(CHAR_SET)\n",
    "\n",
    "IMAGE_HEIGHT = 60\n",
    "IMAGE_WIDTH = 160\n",
    "BATCH_SIZE = 25\n",
    "TFRECORD_FILE = \"captcha/train.tfrecord\"\n",
    "EPOCH = 21\n",
    "SAMPLE_NUM = 5800\n",
    "LOOP_TIMES = EPOCH*SAMPLE_NUM//BATCH_SIZE\n",
    "\n",
    "\n",
    "def read_and_decode(filename,batch_size=BATCH_SIZE,shuffle_batch=True):\n",
    "    min_after_dequeue = 2000\n",
    "    capacity = min_after_dequeue + batch_size*4\n",
    "    filename_queue = tf.train.string_input_producer([filename])\n",
    "    reader = tf.TFRecordReader()\n",
    "    # 返回文件名和文件\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                      features={\n",
    "                                          'image':tf.FixedLenFeature([],tf.string),\n",
    "                                          'label0':tf.FixedLenFeature([],tf.int64),\n",
    "                                          'label1':tf.FixedLenFeature([],tf.int64),\n",
    "                                          'label2':tf.FixedLenFeature([],tf.int64),\n",
    "                                          'label3':tf.FixedLenFeature([],tf.int64)\n",
    "                                      })\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    image = tf.reshape(image,[224,224])\n",
    "    # 预处理\n",
    "    image = tf.cast(image,tf.float32)/255.0\n",
    "    image = tf.subtract(image,0.5)\n",
    "    iamge = tf.multiply(image, 2.0)\n",
    "             \n",
    "    # 获取label\n",
    "    label0 = tf.cast(features['label0'], tf.int32)\n",
    "    label1 = tf.cast(features['label1'], tf.int32)\n",
    "    label2 = tf.cast(features['label2'], tf.int32)\n",
    "    label3 = tf.cast(features['label3'], tf.int32)\n",
    "    if shuffle_batch:\n",
    "        images, labels0, labels1, labels2, labels3 = tf.train.shuffle_batch([image, label0, label1, label2, label3],\n",
    "                                               batch_size=batch_size,\n",
    "                                               capacity=capacity,\n",
    "                                               num_threads=4,\n",
    "                                               min_after_dequeue=min_after_dequeue)\n",
    "    else:\n",
    "        images, labels0, labels1, labels2, labels3 = tf.train.batch([image, label0, label1, label2, label3],\n",
    "                                        batch_size=batch_size,\n",
    "                                        capacity=capacity,\n",
    "                                        num_threads=4,\n",
    "                                         min_after_dequeue=min_after_dequeue)\n",
    "    # 返回图片及字符串形式的验证码，字符串会后面处理                                   \n",
    "    return images, labels0, labels1, labels2, labels3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-008506cfc0d6>:25: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 224, 224])\n",
    "y0 = tf.placeholder(tf.float32, [None])\n",
    "y1 = tf.placeholder(tf.float32, [None])\n",
    "y2 = tf.placeholder(tf.float32, [None])\n",
    "y3 = tf.placeholder(tf.float32, [None])\n",
    "lr = tf.Variable(0.003, dtype = tf.float32)\n",
    "\n",
    "images_batch, labels0_batch, labels1_batch, labels2_batch, labels3_batch = read_and_decode(TFRECORD_FILE,batch_size=BATCH_SIZE)\n",
    "train_network_fn = nets_factory.get_network_fn('alexnet_v2_captcha_multi',\n",
    "                                              num_classes = CHAR_SET_LEN,\n",
    "                                              weight_decay=0.0005,\n",
    "                                              is_training=True)\n",
    "\n",
    "\n",
    "X = tf.reshape(x, [BATCH_SIZE, 224,224,1])\n",
    "logits0, logits1, logits2, logits3, end_points = train_network_fn(X)\n",
    "\n",
    "# 这里的y0,y1,y2,y3 需要索引值，即上面的placeholder需要传入数字\n",
    "one_hot_labels0 = tf.one_hot(indices=tf.cast(y0, tf.int32), depth=CHAR_SET_LEN)\n",
    "one_hot_labels1 = tf.one_hot(indices=tf.cast(y1, tf.int32), depth=CHAR_SET_LEN)\n",
    "one_hot_labels2 = tf.one_hot(indices=tf.cast(y2, tf.int32), depth=CHAR_SET_LEN)\n",
    "one_hot_labels3 = tf.one_hot(indices=tf.cast(y3, tf.int32), depth=CHAR_SET_LEN)\n",
    "\n",
    "# 计算loss\n",
    "loss0 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits0,labels=one_hot_labels0)) \n",
    "loss1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits1,labels=one_hot_labels1)) \n",
    "loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits2,labels=one_hot_labels2)) \n",
    "loss3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits3,labels=one_hot_labels3)) \n",
    "\n",
    "# 计算总的loss\n",
    "total_loss = (loss0+loss1+loss2+loss3)/4.0\n",
    "# 优化total_loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(total_loss) \n",
    "\n",
    "# 计算准确率\n",
    "correct_prediction0 = tf.equal(tf.argmax(one_hot_labels0,1),tf.argmax(logits0,1))\n",
    "accuracy0 = tf.reduce_mean(tf.cast(correct_prediction0,tf.float32))\n",
    "\n",
    "correct_prediction1 = tf.equal(tf.argmax(one_hot_labels1,1),tf.argmax(logits1,1))\n",
    "accuracy1 = tf.reduce_mean(tf.cast(correct_prediction1,tf.float32))\n",
    "\n",
    "correct_prediction2 = tf.equal(tf.argmax(one_hot_labels2,1),tf.argmax(logits2,1))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2,tf.float32))\n",
    "\n",
    "correct_prediction3 = tf.equal(tf.argmax(one_hot_labels3,1),tf.argmax(logits3,1))\n",
    "accuracy3 = tf.reduce_mean(tf.cast(correct_prediction3,tf.float32)) \n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners()\n",
    "    for i in range(LOOP_TIMES):\n",
    "        b_image, b_label0, b_label1 ,b_label2 ,b_label3 = sess.run([images_batch, labels0_batch, labels1_batch, labels2_batch, labels3_batch])\n",
    "        \n",
    "        sess.run(optimizer, feed_dict={x:b_image,\n",
    "                                       y0:b_label0,\n",
    "                                       y1:b_label1,\n",
    "                                       y2:b_label2,\n",
    "                                       y3:b_label3})\n",
    "        if i%20==0:\n",
    "            if i%2000==0:\n",
    "                sess.run(tf.assign(lr,lr/3))\n",
    "            acc0, acc1, acc2, acc3, loss_ = sess.run([accuracy0,accuracy1,accuracy2,accuracy3,total_loss],\n",
    "                                                    feed_dict={\n",
    "                                                        x:b_iamge,\n",
    "                                                        y0:b_label0,\n",
    "                                                       y1:b_label1,\n",
    "                                                       y2:b_label2,\n",
    "                                                       y3:b_label3})\n",
    "            learning_rate = sess.run(lr)\n",
    "            print(\"Iter: %d,  Loss: %.3f,  Accuracy: %.2f, %.2f, %.2f, %.2f, Learning_rate: %.5f\" % (i,loss_,acc0,acc1,acc2,acc3,learning_rate))\n",
    "            if acc0>0.9 and acc1>0.9 and acc2>0.9 and acc3>0.9:\n",
    "                if i%6000==0:\n",
    "                    saver.save(sess,'captcha/models/cap.model',global_step=i)\n",
    "                    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
